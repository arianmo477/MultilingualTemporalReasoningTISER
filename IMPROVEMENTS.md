# Multilingual TISER Extension - Improvements Applied

This document summarizes the improvements and extensions applied to the TISER multilingual extension codebase.

---

## ğŸ¯ Improvements Applied

### 1. **Multilingual Temporal Expression Normalization**

**File:** [`utils/text_processing.py`](utils/text_processing.py)

**What was improved:**
- Extended `normalize_temporal()` function to support language-specific patterns
- Added regex patterns for Italian, German, and Persian temporal expressions

**Before:**
```python
def normalize_temporal(text: str) -> str:
    # Only handled English patterns
    text = _RANGE_RE.sub(r"From \1 to \2", text)
```

**After:**
```python
def normalize_temporal(text: str, language: str = "en") -> str:
    # Supports en, it, de, fa with language-specific patterns
    if language == "it":
        text = _RANGE_RE_IT.sub(r"Dal \1 al \2", text)
    # ... more languages
```

**Impact:**
- Better handling of temporal expressions in each target language
- Improved translation quality for temporal reasoning tasks
- More natural language output

---

### 2. **Translation Quality Validation**

**File:** [`scripts/validate_translation_quality.py`](scripts/validate_translation_quality.py)

**What was added:**
- Automated quality checks for translations
- Entity preservation validation
- Length ratio checks
- CoT structure integrity verification
- Export of problematic samples for manual review

**Features:**
- âœ… Samples random subset for validation
- âœ… Checks entity masking effectiveness
- âœ… Detects translation anomalies
- âœ… Generates detailed reports
- âœ… Exports issues for manual inspection

**Usage:**
```bash
python scripts/validate_translation_quality.py \
    --original data/TISER_train.json \
    --translated data/translated/TISER_train_it.json \
    --language it \
    --sample_size 200 \
    --output validation_report.json
```

---

### 3. **Dataset Statistics and Analysis**

**File:** [`scripts/analyze_dataset_statistics.py`](scripts/analyze_dataset_statistics.py)

**What was added:**
- Comprehensive dataset statistics generation
- Cross-language comparison
- Question type distribution analysis
- Dataset balance metrics

**Metrics Provided:**
- Total samples per language
- Dataset distribution (TGQA, TempReason, TimeQA)
- Question type breakdown
- Average text lengths
- CoT structure coverage
- Side-by-side language comparison

**Usage:**
```bash
python scripts/analyze_dataset_statistics.py \
    --datasets data/TISER_train.json data/translated/TISER_train_it_clean.json \
    --languages en it \
    --output statistics.json
```

---

### 4. **Complete Automation Pipeline**

**File:** [`scripts/run_full_pipeline.sh`](scripts/run_full_pipeline.sh)

**What was added:**
- End-to-end automation for all languages
- Translation â†’ Validation â†’ Preprocessing â†’ Statistics
- Error handling and progress reporting

**Pipeline Steps:**
1. Translates train/test data to all languages
2. Validates translation quality
3. Preprocesses and cleans datasets
4. Generates comprehensive statistics
5. Creates mixed multilingual training set

**Usage:**
```bash
./scripts/run_full_pipeline.sh
```

---

### 5. **Example Scripts for Quick Start**

**Files:**
- [`scripts/example_translate_single_language.sh`](scripts/example_translate_single_language.sh)
- [`scripts/example_validate_and_clean.sh`](scripts/example_validate_and_clean.sh)
- [`scripts/example_analyze_statistics.sh`](scripts/example_analyze_statistics.sh)

**What was added:**
- Quick-start examples for common tasks
- Small sample sizes for testing
- Clear, documented commands

---

### 6. **Comprehensive Documentation**

**Files:**
- [`USAGE.md`](USAGE.md) - Complete usage guide
- [`README.md`](README.md) - Updated with quick start

**What was added:**
- Step-by-step usage instructions
- Troubleshooting guide
- Parameter explanations
- Best practices
- Expected output structure
- Tips for GPU optimization

---

## ğŸ“Š Technical Improvements Summary

### Code Quality
- âœ… Language-agnostic temporal normalization
- âœ… Automated validation pipeline
- âœ… Comprehensive error checking
- âœ… Progress reporting and logging
- âœ… Modular, reusable scripts

### Data Quality
- âœ… Entity preservation checks
- âœ… Translation length validation
- âœ… CoT structure verification
- âœ… Cross-language consistency checks
- âœ… Unknown answer filtering

### Usability
- âœ… One-command full pipeline
- âœ… Example scripts for testing
- âœ… Detailed documentation
- âœ… Clear parameter explanations
- âœ… Troubleshooting guidance

---

## ğŸš€ How to Run

### Quick Test (Single Language, 1000 samples)
```bash
# 1. Translate
./scripts/example_translate_single_language.sh

# 2. Validate and clean
./scripts/example_validate_and_clean.sh

# 3. Analyze
./scripts/example_analyze_statistics.sh
```

### Full Production Pipeline
```bash
# Process all languages with full datasets
./scripts/run_full_pipeline.sh
```

### Manual Step-by-Step
```bash
# 1. Translate
python multilingual_tiser/translation/translate_dataset.py \
    --input data/TISER_train.json \
    --output_dir data/translated \
    --category train \
    --language it \
    --batch_size 8

# 2. Validate
python scripts/validate_translation_quality.py \
    --original data/TISER_train.json \
    --translated data/translated/TISER_train_it.json \
    --language it \
    --sample_size 200 \
    --output validation_report.json

# 3. Clean
python multilingual_tiser/preprocess/validate_tiser_dataset.py \
    --input data/translated/TISER_train_it.json \
    --output data/translated/TISER_train_it_clean.json \
    --split train \
    --prompt_file data/prompts/prompt_it.txt

# 4. Analyze
python scripts/analyze_dataset_statistics.py \
    --datasets data/TISER_train.json data/translated/TISER_train_it_clean.json \
    --languages en it \
    --output statistics.json
```

---

## ğŸ“ Expected Output Structure

After running the full pipeline:

```
data/translated/
â”œâ”€â”€ TISER_train_it.json              # Raw Italian translation
â”œâ”€â”€ TISER_train_it_clean.json        # Cleaned and validated
â”œâ”€â”€ TISER_test_it.json
â”œâ”€â”€ TISER_test_it_clean.json
â”œâ”€â”€ TISER_train_fa.json              # Raw Persian translation
â”œâ”€â”€ TISER_train_fa_clean.json
â”œâ”€â”€ TISER_test_fa.json
â”œâ”€â”€ TISER_test_fa_clean.json
â”œâ”€â”€ TISER_train_de.json              # Raw German translation
â”œâ”€â”€ TISER_train_de_clean.json
â”œâ”€â”€ TISER_test_de.json
â”œâ”€â”€ TISER_test_de_clean.json
â”œâ”€â”€ TISER_train_mixed.json           # Mixed multilingual dataset
â”œâ”€â”€ validation_report_train_it.json  # Quality reports
â”œâ”€â”€ validation_report_train_fa.json
â”œâ”€â”€ validation_report_train_de.json
â”œâ”€â”€ problematic_samples_train_*.json # Issues for review
â”œâ”€â”€ invalid_samples_*.json           # Filtered samples
â””â”€â”€ dataset_statistics.json          # Cross-language analysis
```

---

## ğŸ“ Key Recommendations

### Before Translation
1. **Test with small sample**: Use `--max_samples 100` first
2. **Check GPU memory**: Adjust `--batch_size` accordingly
3. **Verify prompts**: Ensure language-specific prompts are correct

### During Translation
1. **Monitor progress**: Check terminal output for errors
2. **Watch GPU usage**: Use `nvidia-smi` to monitor
3. **Save checkpoints**: Translation is incremental, safe to interrupt

### After Translation
1. **Validate first**: Run quality validation before using data
2. **Review samples**: Manually check 50-100 problematic samples
3. **Check statistics**: Ensure distributions are reasonable
4. **Clean data**: Use preprocessing to remove invalid samples

### For Training
1. **Use cleaned data**: Always use `*_clean.json` files
2. **Balance languages**: Use mixed dataset for cross-lingual models
3. **Monitor metrics**: Track per-language performance separately

---

## âš ï¸ Known Limitations

1. **Translation Model**: Using NLLB-200-distilled-600M (smaller model)
   - Consider upgrading to 1.3B or 3.3B for better quality
   
2. **Temporal Patterns**: Basic regex patterns
   - May miss complex temporal expressions
   - Manual review recommended for edge cases

3. **Entity Masking**: Heuristic-based
   - May not catch all proper names
   - Check validation reports for issues

4. **No Back-Translation**: Quality validation is automated but not exhaustive
   - Manual sampling still recommended

---

## ğŸ“ˆ Quality Metrics to Monitor

After running validation, check:
- **Issue rate**: Should be < 10%
- **Entity preservation**: Should be > 95%
- **Length ratios**: Most should be 0.7-1.5x original
- **CoT structure**: Should be 100% for training data

If metrics are outside these ranges, review problematic samples and consider:
- Adjusting entity masking patterns
- Using larger translation model
- Manual correction of critical samples

---

## ğŸ”„ Integration with Training Pipeline

The cleaned datasets are ready to use with your training pipeline:

```python
# Example: Load cleaned multilingual data
from utils.utils import load_json

train_en = load_json("data/TISER_train.json")
train_it = load_json("data/translated/TISER_train_it_clean.json")
train_fa = load_json("data/translated/TISER_train_fa_clean.json")
train_mixed = load_json("data/translated/TISER_train_mixed.json")

# Each sample has:
# - question: translated question
# - answer: translated answer
# - prompt: language-specific CoT prompt
# - output: translated reasoning (training only)
# - language: language code
```

---

## ğŸ¯ Next Steps

1. **Run Full Pipeline**: Execute `./scripts/run_full_pipeline.sh`
2. **Review Reports**: Check validation reports in `data/translated/`
3. **Manual Sampling**: Review 100 samples per language manually
4. **Train Models**: Use cleaned data with your training pipeline
5. **Evaluate**: Test on multilingual test sets
6. **Iterate**: Adjust based on quality metrics and performance

---

For detailed usage instructions, see [USAGE.md](USAGE.md).
For quick reference, see [README.md](README.md).
